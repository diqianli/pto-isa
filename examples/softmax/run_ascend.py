#!/usr/bin/env python3
"""
PTO Example Runner - softmax

Auto-generated by config_example.py
Configuration:
- Target Platform: ascend_a2a3
- Binary Expansion: True
- Record & Replay: True
- Task Dump: True
- Task Graph PDF: True
- Performance Benchmark: False
- Test Range: 1 - 1024 (step: 1)
- Accuracy Test: False
- Simulation: False
"""

import os
import sys
import time
import json
import subprocess
from datetime import datetime

# =============================================================================
# Path Setup
# =============================================================================

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.dirname(os.path.dirname(SCRIPT_DIR))
SRC_DIR = os.path.join(ROOT_DIR, "src")
RUNTIME_DIR = os.path.join(SRC_DIR, "runtime")
OUTPUT_DIR = os.path.join(SCRIPT_DIR, "output")

sys.path.insert(0, SRC_DIR)

# =============================================================================
# Configuration
# =============================================================================

CONFIG = {
    "example_name": "softmax",
    "target_platform": "ascend_a2a3",
    "enable_binary_expansion": True,
    "enable_task_dump": True,
    "enable_task_graph_pdf": True,
    "enable_perf_benchmark": False,
    "test_input_min": 1,
    "test_input_max": 1024,
    "test_input_step": 1,
    "enable_accuracy_test": False,
    "enable_simulation": False,
    "num_warmup_iterations": 3,
    "num_benchmark_iterations": 10,
}

# =============================================================================
# Imports
# =============================================================================

try:
    from compile.pto_compile import (
        PTOFunctionBuilder, PTOModule, MultiBackendCodeGenerator,
        generate_arm64_code, generate_cuda_code, generate_ascend_code,
    )
    from isa_definition.pto_isa_definition import ElementType, MemorySpace
except ImportError as e:
    print(f"Error importing PTO modules: {e}")
    print("Make sure you're running from the correct directory.")
    sys.exit(1)

# =============================================================================
# Utility Functions
# =============================================================================

def print_header(title):
    print("\n" + "=" * 60)
    print(f"  {title}")
    print("=" * 60)


def ensure_dir(path):
    os.makedirs(path, exist_ok=True)
    return path


def run_command(cmd, cwd=None, timeout=300):
    """Run a shell command and return result."""
    try:
        result = subprocess.run(
            cmd, shell=True, cwd=cwd,
            capture_output=True, text=True, timeout=timeout
        )
        return result.returncode == 0, result.stdout, result.stderr
    except subprocess.TimeoutExpired:
        return False, "", "Command timed out"
    except Exception as e:
        return False, "", str(e)


# =============================================================================
# Code Generation
# =============================================================================

def generate_code():
    """Generate code for the target platform."""
    print_header("Code Generation")
    
    # Import the example module
    example_module_name = None
    for f in os.listdir(SCRIPT_DIR):
        if f.startswith('pto_') and f.endswith('.py') and f != 'run.py':
            example_module_name = f[:-3]
            break
    
    if not example_module_name:
        print("Error: No pto_*.py example file found!")
        return False
    
    print(f"  Loading example: {example_module_name}")
    
    # Import and run the example's main function
    sys.path.insert(0, SCRIPT_DIR)
    try:
        example_module = __import__(example_module_name)
        
        # Look for create_*_module functions first (for direct code generation)
        create_module_func = None
        for attr_name in dir(example_module):
            if attr_name.startswith('create_') and attr_name.endswith('_module'):
                create_module_func = getattr(example_module, attr_name)
                break
        
        if create_module_func is None and hasattr(example_module, 'create_module'):
            create_module_func = example_module.create_module
        
        # Always prefer create_*_module for code generation when available
        platform = CONFIG['target_platform']
        use_direct_generation = (create_module_func is not None)
        
        if use_direct_generation:
            print(f"  Creating module using {create_module_func.__name__}()...")
            module = create_module_func()
            
            # Generate code - put source files in generated_code/ subfolder
            platform_dir = ensure_dir(os.path.join(OUTPUT_DIR, platform))
            code_dir = ensure_dir(os.path.join(platform_dir, "generated_code"))
            
            gen = MultiBackendCodeGenerator(
                enable_fusion=True,
                analyze_buffers=True,
                module=module
            )
            
            for func_name, prog in module.functions.items():
                print(f"  Generating {platform} code for: {func_name}")
                
                if platform == "arm64":
                    code = gen.generate_arm64(prog)
                    ext = ".c"
                elif platform == "ascend_a2a3_sim":
                    code = gen.generate_ascend_a2a3_sim(prog)
                    ext = ".c"
                elif platform == "cuda":
                    code = gen.generate_cuda(prog)
                    ext = ".cu"
                else:  # ascend
                    code = gen.generate_ascend(prog)
                    ext = ".cpp"
                
                output_file = os.path.join(code_dir, f"{func_name}{ext}")
                with open(output_file, 'w') as f:
                    f.write(code)
                print(f"    -> {output_file}")
        elif hasattr(example_module, 'main'):
            print("  Running example main()...")
            example_module.main()
        else:
            print("  Warning: No main() or create_*_module() found, running module...")
            
    except Exception as e:
        print(f"  Error: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("  Code generation complete!")
    return True


# =============================================================================
# Compilation
# =============================================================================

def compile_code():
    """Compile generated code."""
    print_header("Compilation")
    
    platform = CONFIG['target_platform']
    platform_dir = os.path.join(OUTPUT_DIR, platform)
    code_dir = os.path.join(platform_dir, "generated_code")
    
    if not os.path.exists(code_dir):
        print(f"  No generated code found in {code_dir}")
        return False
    
    # Find orchestration file by checking:
    # 1. 'orchestration' in filename
    # 2. 'Function Type: Orchestration' in file header
    # 3. 'int main(' in file (for simulator)
    orch_file = None
    for f in os.listdir(code_dir):
        if f.endswith('.c'):
            fpath = os.path.join(code_dir, f)
            if 'orchestration' in f:
                orch_file = fpath
                break
            try:
                with open(fpath, 'r') as fp:
                    # Read first 500 chars for header check
                    header = fp.read(500)
                    if 'Function Type: Orchestration' in header:
                        orch_file = fpath
                        break
                    if 'int main(' in header:
                        orch_file = fpath
                        break
            except:
                pass
    
    if not orch_file:
        print("  No orchestration file found to compile")
        return True  # Not an error, just no orchestration
    
    print(f"  Compiling: {os.path.basename(orch_file)}")
    
    # Build compile command - output executable to platform_dir (not code_dir)
    exe_basename = os.path.basename(orch_file).replace('.c', '')
    exe_path = os.path.join(platform_dir, exe_basename)
    
    compile_flags = ["-O2", "-std=c11"]
    if CONFIG['enable_binary_expansion']:
        compile_flags.append("-DPTO_BINARY_EXPANSION")
    if CONFIG['enable_task_dump']:
        compile_flags.append("-DPTO_TASK_DUMP")
    
    cmd = f"gcc {' '.join(compile_flags)} -I{RUNTIME_DIR} -o {exe_path} {orch_file} -lpthread"
    
    print(f"  Command: {cmd}")
    success, stdout, stderr = run_command(cmd, cwd=platform_dir)
    
    if success:
        print(f"  Compiled successfully: {exe_path}")
        return True
    else:
        print(f"  Compilation failed: {stderr}")
        return False


# =============================================================================
# Task Dump and Statistics
# =============================================================================

def run_task_dump():
    """Run and collect task dump statistics."""
    if not CONFIG['enable_task_dump']:
        return True
    
    print_header("Task Dump & Statistics")
    
    platform = CONFIG['target_platform']
    platform_dir = os.path.join(OUTPUT_DIR, platform)
    
    # Find executable
    exe_file = None
    for f in os.listdir(platform_dir):
        if not f.endswith(('.c', '.cu', '.cpp', '.txt', '.pdf', '.json', '.h')):
            exe_path = os.path.join(platform_dir, f)
            if os.access(exe_path, os.X_OK):
                exe_file = exe_path
                break
    
    if not exe_file:
        print("  No executable found")
        return False
    
    print(f"  Running: {os.path.basename(exe_file)}")
    success, stdout, stderr = run_command(exe_file, cwd=platform_dir, timeout=60)
    
    if success:
        print("  Execution successful")
        if stdout:
            print("  Output:")
            for line in stdout.split('\n')[:20]:
                print(f"    {line}")
        
        # Look for dump file
        dump_file = exe_file.replace('_orchestration', '_task_graph') + '.txt'
        if os.path.exists(dump_file):
            print(f"\n  Task graph dump: {dump_file}")
            analyze_task_dump(dump_file)
    else:
        print(f"  Execution failed: {stderr}")
    
    return success


def analyze_task_dump(dump_file):
    """Analyze task dump file and print statistics."""
    print("\n  Task Dump Statistics:")
    print("  " + "-" * 40)
    
    try:
        with open(dump_file, 'r') as f:
            content = f.read()
        
        # Count tasks
        task_count = content.count("Task ")
        print(f"    Total tasks: {task_count}")
        
        # Count by type if available
        lines = content.split('\n')
        task_types = {}
        for line in lines:
            if "func=" in line:
                # Extract function name
                start = line.find("func=") + 5
                end = line.find(",", start) if "," in line[start:] else len(line)
                func_name = line[start:end].strip('"')
                task_types[func_name] = task_types.get(func_name, 0) + 1
        
        if task_types:
            print("    Tasks by function:")
            for func, count in sorted(task_types.items(), key=lambda x: -x[1]):
                print(f"      {func}: {count}")
        
        # Dependency info
        dep_count = content.count("fanin=")
        print(f"    Dependencies tracked: {dep_count}")
        
    except Exception as e:
        print(f"    Error analyzing dump: {e}")


# =============================================================================
# Task Graph PDF Generation
# =============================================================================

def generate_task_graph_pdf():
    """Generate task graph visualization as PDF."""
    if not CONFIG['enable_task_graph_pdf']:
        return True
    
    print_header("Task Graph PDF Generation")
    
    # Check if graphviz is available
    success, _, _ = run_command("which dot")
    if not success:
        print("  Warning: graphviz not installed, skipping PDF generation")
        return True
    
    platform = CONFIG['target_platform']
    platform_dir = os.path.join(OUTPUT_DIR, platform)
    
    # Look for task graph txt file
    txt_file = None
    for f in os.listdir(platform_dir):
        if 'task_graph' in f and f.endswith('.txt'):
            txt_file = os.path.join(platform_dir, f)
            break
    
    if not txt_file:
        print("  No task graph file found")
        return True
    
    # Try to use visualize_taskgraph.py if available
    vis_script = os.path.join(ROOT_DIR, "visualize_taskgraph.py")
    if os.path.exists(vis_script):
        print(f"  Using visualize_taskgraph.py")
        cmd = f"python3 {vis_script} {txt_file}"
        success, stdout, stderr = run_command(cmd)
        if success:
            pdf_file = txt_file.replace('.txt', '.pdf')
            print(f"  Generated: {pdf_file}")
        else:
            print(f"  Warning: PDF generation failed: {stderr}")
    else:
        print("  visualize_taskgraph.py not found")
    
    return True


# =============================================================================
# Performance Benchmark
# =============================================================================

def run_performance_benchmark():
    """Run performance benchmark for orchestration dispatch speed."""
    if not CONFIG['enable_perf_benchmark']:
        return True
    
    print_header("Performance Benchmark")
    
    platform = CONFIG['target_platform']
    platform_dir = os.path.join(OUTPUT_DIR, platform)
    
    # Find executable
    exe_file = None
    for f in os.listdir(platform_dir):
        if 'orchestration' in f and not f.endswith(('.c', '.cu', '.cpp', '.txt', '.pdf')):
            exe_path = os.path.join(platform_dir, f)
            if os.access(exe_path, os.X_OK):
                exe_file = exe_path
                break
    
    if not exe_file:
        print("  No executable found for benchmarking")
        return False
    
    print(f"  Benchmarking: {os.path.basename(exe_file)}")
    print(f"  Warmup iterations: {CONFIG['num_warmup_iterations']}")
    print(f"  Benchmark iterations: {CONFIG['num_benchmark_iterations']}")
    
    # Warmup
    print("\n  Warming up...")
    for i in range(CONFIG['num_warmup_iterations']):
        run_command(exe_file, cwd=platform_dir, timeout=60)
    
    # Benchmark
    print("  Running benchmark...")
    times = []
    for i in range(CONFIG['num_benchmark_iterations']):
        start = time.perf_counter()
        success, _, _ = run_command(exe_file, cwd=platform_dir, timeout=60)
        end = time.perf_counter()
        
        if success:
            times.append((end - start) * 1000)  # Convert to ms
            print(f"    Iteration {i+1}: {times[-1]:.2f} ms")
        else:
            print(f"    Iteration {i+1}: FAILED")
    
    if times:
        avg_time = sum(times) / len(times)
        min_time = min(times)
        max_time = max(times)
        
        print("\n  Results:")
        print(f"    Average: {avg_time:.2f} ms")
        print(f"    Min:     {min_time:.2f} ms")
        print(f"    Max:     {max_time:.2f} ms")
        
        # Save results
        results = {
            "timestamp": datetime.now().isoformat(),
            "executable": os.path.basename(exe_file),
            "warmup_iterations": CONFIG['num_warmup_iterations'],
            "benchmark_iterations": CONFIG['num_benchmark_iterations'],
            "times_ms": times,
            "avg_ms": avg_time,
            "min_ms": min_time,
            "max_ms": max_time,
        }
        
        results_file = os.path.join(platform_dir, "benchmark_results.json")
        with open(results_file, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"\n  Results saved to: {results_file}")
    
    return True


# =============================================================================
# Accuracy Test
# =============================================================================

def run_accuracy_test():
    """Generate and run accuracy tests."""
    if not CONFIG['enable_accuracy_test']:
        return True
    
    print_header("Accuracy Test")
    print("  Accuracy testing not yet implemented")
    print("  (Requires reference implementation)")
    return True


# =============================================================================
# Simulation and Trace Generation
# =============================================================================

def run_simulation():
    """Run simulation and generate trace files."""
    if not CONFIG['enable_simulation']:
        return True
    
    print_header("Simulation & Trace Generation")
    
    if CONFIG['target_platform'] != 'ascend_a2a3_sim':
        print("  Simulation only available for ascend_a2a3_sim platform")
        return True
    
    platform_dir = os.path.join(OUTPUT_DIR, CONFIG['target_platform'])
    
    # Find simulation executable
    exe_file = None
    for f in os.listdir(platform_dir):
        if 'orchestration' in f and not f.endswith(('.c', '.cu', '.cpp', '.txt', '.pdf')):
            exe_path = os.path.join(platform_dir, f)
            if os.access(exe_path, os.X_OK):
                exe_file = exe_path
                break
    
    if not exe_file:
        print("  No simulation executable found")
        return False
    
    print(f"  Running simulation: {os.path.basename(exe_file)}")
    
    # Run with trace enabled
    env = os.environ.copy()
    env['PTO_TRACE_OUTPUT'] = os.path.join(platform_dir, 'trace.json')
    
    success, stdout, stderr = run_command(exe_file, cwd=platform_dir, timeout=120)
    
    if success:
        trace_file = os.path.join(platform_dir, 'trace.json')
        if os.path.exists(trace_file):
            print(f"  Trace file generated: {trace_file}")
            
            # Basic trace analysis
            try:
                with open(trace_file, 'r') as f:
                    trace_data = json.load(f)
                if isinstance(trace_data, list):
                    print(f"  Trace events: {len(trace_data)}")
            except:
                pass
        else:
            print("  Note: Trace file not generated (may need runtime support)")
    else:
        print(f"  Simulation failed: {stderr}")
    
    return success


# =============================================================================
# Main
# =============================================================================

def main():
    print_header(f"PTO Example Runner: {CONFIG['example_name']}")
    print(f"  Platform: {CONFIG['target_platform']}")
    print(f"  Output:   {OUTPUT_DIR}")
    
    ensure_dir(OUTPUT_DIR)
    
    steps = [
        ("Code Generation", generate_code),
        ("Compilation", compile_code),
        ("Task Dump", run_task_dump),
        ("Task Graph PDF", generate_task_graph_pdf),
        ("Performance Benchmark", run_performance_benchmark),
        ("Accuracy Test", run_accuracy_test),
        ("Simulation", run_simulation),
    ]
    
    results = []
    for name, func in steps:
        try:
            success = func()
            results.append((name, success))
        except Exception as e:
            print(f"  Error in {name}: {e}")
            results.append((name, False))
    
    print_header("Summary")
    for name, success in results:
        status = "✓ OK" if success else "✗ FAILED"
        print(f"  {name}: {status}")
    
    print("\nDone!")


if __name__ == "__main__":
    main()
